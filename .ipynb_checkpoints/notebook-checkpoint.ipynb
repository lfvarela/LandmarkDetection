{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d17c37b8c661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m \u001b[0;31m# linear algebra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m \u001b[0;31m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "print(os.listdir(\"../input/landmark-recognition-challenge\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Exploratory Analysis :\n",
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c28b660a-f713-41fb-b42c-baf78d8e9978",
    "_uuid": "ebf1af925d7892dbb7a5830da88bb575c123dec7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_data = pd.read_csv('../input/landmark-recognition-challenge/train.csv')\n",
    "train_data = pd.read_csv('../input/landmark-dataset-url-analysis/trainsmall.csv')\n",
    "test_data = pd.read_csv('../input/landmark-recognition-challenge/test.csv')\n",
    "submission = pd.read_csv(\"../input/landmark-recognition-challenge/sample_submission.csv\")\n",
    "train_data['id'] = train_data['id'].astype('category')\n",
    "train_data['url'] = train_data['url'].astype('category')\n",
    "train_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9840fd78-dd5f-41f8-baba-0c1d46a330f2",
    "_uuid": "18250a1e698290545e98b20e6bc9b9ada52e8288",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.info(); print(\"-\" * 20);\n",
    "test_data.info(); print(\"-\" * 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8bef751f-7018-4f4a-80da-66c719e03502",
    "_uuid": "dfde3393653fe985c23fe6d8b0ce5343e7bc7410",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -> We can see that there are no missing values in both test and train data\n",
    "print(\"Unique values in Train :\\n\",train_data.nunique())\n",
    "print(\"Unique values in Test :\\n\",test_data.nunique())\n",
    "\n",
    "# -> In the train dataset, there are only 14951 unique landmark_id data. All id's and url's are unique.\n",
    "# -> All id's and url's are unique in the test data as well.\n",
    "\n",
    "# Concatenate Train and test data\n",
    "concatenated = pd.concat([train_data, test_data])\n",
    "print(\"The shape of the resulted DataFrame: \",concatenated.shape)\n",
    "concatenated.nunique()\n",
    "\n",
    "# -> All id's and url's are unique for the concatenated data. That means we do not have any id's or url's from train dataset leaked in the test data set as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d29898f5-f1bb-4d76-b9c3-197d6d7e73a6",
    "_uuid": "0d5f11fc4c0e1addc94d25b9ab8964248ff45517",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Occurance of landmark_id in decreasing order(Top categories)\n",
    "IMAGES_NUMBER = 50\n",
    "#temp = pd.DataFrame(train_data.landmark_id.value_counts().tail(40))\n",
    "temp = pd.DataFrame(train_data.landmark_id.value_counts().head(IMAGES_NUMBER))\n",
    "temp.reset_index(inplace=True)\n",
    "temp.columns = ['landmark_id','count']\n",
    "\n",
    "# Plot the most frequent landmark_ids\n",
    "plt.figure(figsize = (25, 8))\n",
    "plt.title('Most frequent landmarks')\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x=\"landmark_id\", y=\"count\", data=temp)\n",
    "plt.show()\n",
    "\n",
    "# -> The most frequent landmark_id is 9633 and the count is 50337.\n",
    "# -> There are many least frequent landmarks whose count is 1\n",
    "\n",
    "plt.figure(figsize=(25, 8))\n",
    "plt.title(\"Category distribution\")\n",
    "sns.distplot(train_data[\"landmark_id\"], bins=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"Number of classes under 25 occurence \",(train_data[\"landmark_id\"].value_counts() <= 25).sum() ,\" of \", len(train_data[\"landmark_id\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "28520e63-4e23-4fc2-8789-48a87b8c9a31",
    "_uuid": "bf7d60b3abdd4324aa255dfbbf76973174b8af2d"
   },
   "source": [
    "# Display some images from URLs / Some URLs Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d1d11755-3213-4e32-9ca5-748c681cc932",
    "_uuid": "1a0eae82c549d00b3b6fe5097e59ad3c68bad9a7",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "def displayLandmarkImagesLarge(urls, category_name):\n",
    "    img_style = \"width: 200px; height:160px; margin: 0px; float: left; border: 1px solid black;\"\n",
    "    images_list = ''.join([f\"<img style='{img_style}' src='{u}' />\" for _, u in urls.head(12).iteritems()])\n",
    "    display(HTML(images_list))\n",
    "\n",
    "category = train_data['landmark_id'].value_counts().keys()[15]\n",
    "urls = train_data[train_data['landmark_id'] == category]['url']\n",
    "displayLandmarkImagesLarge(urls, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "50278ddc-05a6-41e6-a8fa-3e6dda62b0da",
    "_uuid": "531a0c757477d5f8c4177c15d426802ff684bb3f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize 6 images for each of the first 5 landmarks, ordered by the number of occurences.\n",
    "LANDMARK_NUMBER = 5\n",
    "IMAGES_NUMBER = 6\n",
    "landMarkIDs = pd.Series(train_data['landmark_id'].value_counts().keys())[1:LANDMARK_NUMBER+1]\n",
    "for landMarkID in landMarkIDs:\n",
    "    url = train_data[train_data['landmark_id'] == landMarkID]['url'].head(IMAGES_NUMBER)\n",
    "    displayLandmarkImagesLarge(url, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "16c854db-a8d4-4951-8846-9bbec4056a52",
    "_uuid": "81935c2a5e95faec2691acd82a0b889cfc7eb74f",
    "collapsed": true
   },
   "source": [
    "# Extracting website name and adding new Column \"site_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1114d2bc-3fb5-47cd-bfad-1069a0eb826b",
    "_uuid": "b0c9e66a452f73ee5ba9a0597ee50a5a4d45c687",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract site_names from train data\n",
    "temp_list = list()\n",
    "for path in train_data['url']:\n",
    "    temp_list.append((path.split('//',1)[1]).split('/', 1)[0])\n",
    "train_data['site_name'] = temp_list\n",
    "# Extract site_names from test data\n",
    "temp_list = list()\n",
    "for path in test_data['url']:\n",
    "    temp_list.append((path.split('//', 1)[1]).split('/',1)[0])\n",
    "test_data['site_name'] = temp_list\n",
    "\n",
    "# Occurence of site in decreasing order(Top categories)\n",
    "temp_train = pd.DataFrame(train_data.site_name.value_counts())\n",
    "temp_test = pd.DataFrame(test_data.site_name.value_counts())\n",
    "\n",
    "temp_train.reset_index(inplace= True); temp_test.reset_index(inplace= True)\n",
    "temp_train.columns = temp_test.columns = ['site_name', 'count']\n",
    "# Plot The sites with teir count\n",
    "def draw_plot_site_names(SData):\n",
    "    plt.figure(figsize=(25, 8))\n",
    "    plt.title('Sites with their count')\n",
    "    sns.set_color_codes(\"pastel\")\n",
    "    sns.barplot(x=\"site_name\", y=\"count\", data=SData, label=\"Count\")\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.setp(labels, rotation=90)\n",
    "    plt.show()\n",
    "draw_plot_site_names(temp_train)\n",
    "draw_plot_site_names(temp_test)\n",
    "# Total unique sites are 16 in train and 25 in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e877ba1b-19ce-4da8-82e2-93812ac52357",
    "_uuid": "140c8974ec3768ddab61aef9adad39814153dc13",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the expected format for the submission file\n",
    "submission.head(6)\n",
    "\n",
    "# -> Submission has two columns : an landmark id that is associated with the image and its corresponding confidence score.\n",
    "# -- Some query images may contain no landmarks. For these, one can submit no landmark id (and no confidence score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d50761c4-a1fb-425a-bed8-bd36a0ba4dbb",
    "_uuid": "0d68b53c09f2ed908c0b3917aca9d5bde0417fec"
   },
   "source": [
    "# Random Guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4b3c2937-21f4-4429-869c-d77a655bed80",
    "_uuid": "c8d9ad6085cd9b5d5f98fcf8cb570435bb76f4dd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take the most frequent label\n",
    "def_guess = train_data['landmark_id'].value_counts()/train_data['landmark_id'].value_counts().sum()\n",
    "\n",
    "np.random.seed=15\n",
    "r_idx = lambda : np.random.choice(def_guess.index, p = def_guess.values)\n",
    "\n",
    "r_score = lambda idx: '%d %2.4f' % (def_guess.index[idx], def_guess.values[idx])\n",
    "submission['landmarks'] = submission.id.map(lambda _: r_score(r_idx()))\n",
    "submission.to_csv('rand_submission.csv', index=False)\n",
    "submission.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bb4f4a5e-c979-4fd0-a0c5-f7c6f1e91a45",
    "_uuid": "db0a44a1313e1d6361c86d15ae7c078f0ef6a56e",
    "collapsed": true
   },
   "source": [
    "Reference: \n",
    "* [https://www.kaggle.com/codename007/a-very-extensive-landmark-exploratory-analysis](https://www.kaggle.com/codename007/a-very-extensive-landmark-exploratory-analysis)\n",
    "* [https://www.kaggle.com/gpreda/google-landmark-recogn-challenge-data-exploration](https://www.kaggle.com/gpreda/google-landmark-recogn-challenge-data-exploration)\n",
    "* [https://www.kaggle.com/kmader/baseline-landmark-model](https://www.kaggle.com/kmader/baseline-landmark-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f9126a64-d9df-40c3-810b-f5f77018e23d",
    "_uuid": "a772819ae088668d48cb0979bfc0978334f8b9cb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import random\n",
    "#random.seed = 22\n",
    "#np.random.seed = 22\n",
    "#for i in range(5):\n",
    "#    vals = train_data.landmark_id.value_counts().index\n",
    "#    submission['landmarks'] = submission['landmarks'].map(lambda x: ' '.join(map(str, [random.choice(vals), round(random.random(), 2)])))\n",
    "#    submission.to_csv('submission' + str(i+1).zfill(2) +'.csv', index=False)\n",
    "#    submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "77768930-3bb6-4b98-9ad4-40c40dab08f5",
    "_uuid": "3fa9087f3e3e44d410f6d4cf250c03739af8057e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use only the first 1000 most frequent landmarks in train set for building the test set values\n",
    "import pylab as pl\n",
    "pl.seed = 0\n",
    "N = 1500\n",
    "probs = train_data.landmark_id.value_counts() / train_data.shape[0]\n",
    "probs = probs.iloc[:N]\n",
    "probs = pd.DataFrame({'landmark_id': probs.index,\n",
    "                      'probability': probs.values}, index=pl.arange(N))\n",
    "T = pd.merge(train_data, probs, on='landmark_id', how='inner')\n",
    "inx = pl.randint(0, T.shape[0], submission.shape[0])\n",
    "submission['landmark_id'] = T.landmark_id.iloc[inx].values\n",
    "submission['prob'] = T.probability.iloc[inx].values\n",
    "submission['landmarks'] = submission.landmark_id.astype(str) + ' ' + submission.prob.astype(str)\n",
    "submission[['id','landmarks']].to_csv('submission_MFreq.csv', index=False)\n",
    "submission[['id','landmarks']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c8a3c645-76ee-4b54-b611-43c063a7e8fd",
    "_uuid": "c52685ff914b243cb3ecd2c821a02d0510fe6352",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
